{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228dea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "DATA_RAW = (NOTEBOOK_DIR / \"../data/raw\").resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095fac9",
   "metadata": {},
   "source": [
    "## Step 1: Load CSV\n",
    "\n",
    "Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3022e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\miga\\\\Documents\\\\GitHub\\\\Project_EDSB\\\\Sandbox\\\\data\\\\raw\\\\Telco_customer_churn_demographics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load all CSV files\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m demographics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(DATA_RAW \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTelco_customer_churn_demographics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m location     \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(DATA_RAW \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTelco_customer_churn_location.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m population   \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(DATA_RAW \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTelco_customer_churn_population.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\miga\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\miga\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\miga\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\miga\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\miga\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\miga\\\\Documents\\\\GitHub\\\\Project_EDSB\\\\Sandbox\\\\data\\\\raw\\\\Telco_customer_churn_demographics.csv'"
     ]
    }
   ],
   "source": [
    "# Load all CSV files\n",
    "demographics = pd.read_csv(DATA_RAW / \"Telco_customer_churn_demographics.csv\")\n",
    "location     = pd.read_csv(DATA_RAW / \"Telco_customer_churn_location.csv\")\n",
    "population   = pd.read_csv(DATA_RAW / \"Telco_customer_churn_population.csv\")\n",
    "services     = pd.read_csv(DATA_RAW / \"Telco_customer_churn_services.csv\")\n",
    "status       = pd.read_csv(DATA_RAW / \"Telco_customer_churn_status.csv\")\n",
    "\n",
    "# Quick shapes to confirm they loaded\n",
    "for name, df in {\n",
    "    \"Demographics\": demographics,\n",
    "    \"Location\": location,\n",
    "    \"Population\": population,\n",
    "    \"Services\": services,\n",
    "    \"Status\": status,\n",
    "}.items():\n",
    "    print(f\"{name:12s} -> {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12bcf84",
   "metadata": {},
   "source": [
    "## Step 2: Initial Data Exploration\n",
    "\n",
    "Before merging the datasets, it's important to understand what each table represents\n",
    "and how they relate to one another.  \n",
    "We'll start by exploring them individually to inspect their structure, size, and key variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Demographics\": demographics,\n",
    "    \"Location\": location,\n",
    "    \"Population\": population,\n",
    "    \"Services\": services,\n",
    "    \"Status\": status,\n",
    "}\n",
    "\n",
    "# Print shape and preview each dataset\n",
    "for name, df in datasets.items():\n",
    "    print(f\"===== {name} =====\")\n",
    "    print(f\"Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    display(df.head(3))\n",
    "    print(\"\\nColumn names:\\n\", list(df.columns))\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ae8b0",
   "metadata": {},
   "source": [
    "### Step 2.1: Data Overview and Descriptive Statistics\n",
    "\n",
    "Now that we have inspected each dataset‚Äôs structure, we‚Äôll examine their **data types**, \n",
    "**numeric distributions**, and **categorical summaries**.  \n",
    "This step helps identify potential data-quality issues, redundant columns, and \n",
    "features that might need cleaning or transformation later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45bde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined data overview (includes .info, describe, missing, uniques)\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{'=' * 25} {name} {'=' * 25}\")\n",
    "    print(f\"Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\\n\")\n",
    "\n",
    "    # --- 1Ô∏è‚É£ Data types and non-null counts\n",
    "    print(\"üìò Data Types & Non-Null Values:\")\n",
    "    df.info()\n",
    "\n",
    "    # Identify numeric & categorical columns\n",
    "    num_cols = df.select_dtypes(include=\"number\").columns\n",
    "    cat_cols = df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns\n",
    "\n",
    "    # --- 2Ô∏è‚É£ Numeric summary\n",
    "    if len(num_cols) > 0:\n",
    "        print(\"\\nüìä Numeric Summary:\")\n",
    "        display(df[num_cols].describe().T)\n",
    "    else:\n",
    "        print(\"\\nüìä Numeric Summary: (none)\")\n",
    "\n",
    "    # --- 3Ô∏è‚É£ Categorical summary\n",
    "    if len(cat_cols) > 0:\n",
    "        print(\"\\nüî† Categorical Summary:\")\n",
    "        display(df[cat_cols].describe().T)\n",
    "    else:\n",
    "        print(\"\\nüî† Categorical Summary: (none)\")\n",
    "\n",
    "    # --- 4Ô∏è‚É£ Missing & unique values\n",
    "    print(\"\\nüßπ Missing Values (Top 10):\")\n",
    "    display(df.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "    print(\"üî¢ Unique Values (Top 10):\")\n",
    "    display(df.nunique().sort_values(ascending=False).head(10).to_frame(\"nunique\"))\n",
    "\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a4f1f",
   "metadata": {},
   "source": [
    "## **Observations**\n",
    "\n",
    "### **Demographics:**  \n",
    "\n",
    "The **Demographics** dataset contains information describing each customer‚Äôs personal and family profile.  \n",
    "It includes **7,043 customers** and **9 variables** ‚Äî 3 numeric (`Count`, `Age`, `Number of Dependents`) and 6 categorical.\n",
    "\n",
    "**Key takeaways:**\n",
    "\n",
    "- **Data quality:**  \n",
    "  - No missing values across any column.  \n",
    "  - Data types are correctly assigned (`int64` for numeric, `object` for categorical).  \n",
    "\n",
    "- **Numeric overview:**  \n",
    "  - `Count` is constant (=1) ‚Üí non-informative and can be dropped later.  \n",
    "  - `Age` ranges from **19 to 80** (mean ‚âà 46.5 years).  \n",
    "  - `Number of Dependents` ranges from **0 to 9**, with an average of 0.47 - which means that most customers have few or no dependents.  \n",
    "\n",
    "- **Categorical overview:**  \n",
    "  - Gender distribution is balanced (Male ‚âà 3.6k, Female ‚âà 3.5k).  \n",
    "  - Most customers are **not married** (‚âà 52%).  \n",
    "  - About **84% are not senior citizens** and **80% are not under 30**, suggesting the typical customer is middle-aged.  \n",
    "  - Dependents are mostly ‚ÄúNo‚Äù (‚âà 77%).  \n",
    "\n",
    "**Interpretation:**  \n",
    "This table provides socio-demographic context for each customer, which may influence churn behaviour.  \n",
    "Variables such as **Age**, **Senior Citizen**, and **Dependents** could serve as useful predictors, while `Count` is non-informative.  \n",
    "`Under 30` may be redundant (as it is derived from `Age`), but it will be **kept for interpretability** and to facilitate descriptive comparisons between age groups.\n",
    "\n",
    "\n",
    "\n",
    "### **Location:**  \n",
    "\n",
    "The **Location** dataset provides geographic and positional information for each customer.  \n",
    "It includes **7,043 customers** and **9 variables**, with 3 numeric columns (`Count`, `Zip Code`, `Latitude`, `Longitude`) and 5 categorical columns.\n",
    "\n",
    "**Key takeaways:**\n",
    "- **Data quality:**  \n",
    "  - No missing values.  \n",
    "  - Data types are appropriate (`object` for text, `int64` and `float64` for numeric).  \n",
    "\n",
    "- **Numeric overview:**  \n",
    "  - `Count` is constant (=1) - can be dropped.  \n",
    "  - `Zip Code` ranges from **90001 to 96150**, covering southern and northern California regions.  \n",
    "  - Latitude and longitude values confirm all customers are located within **California, United States**.\n",
    "\n",
    "- **Categorical overview:**  \n",
    "  - `Country` = ‚ÄúUnited States‚Äù and `State` = ‚ÄúCalifornia‚Äù for all records.  \n",
    "  - `City` has **1,106 unique values**, with Los Angeles being the most frequent (293 customers).  \n",
    "  - `Lat Long` is a textual combination of latitude and longitude, redundant given the numeric columns.  \n",
    "\n",
    "**Interpretation:**  \n",
    "This table adds **geospatial context** to the dataset.  \n",
    "It allows customer-level geographic segmentation (e.g., by city or ZIP code) and later enables merging with **Population** data using `Zip Code`.  \n",
    "Columns like `Lat Long` and `Count` are redundant, while `Zip Code` serves as a key linking variable to external demographic data.\n",
    "\n",
    "\n",
    "\n",
    "### **Population:**  \n",
    "\n",
    "The **Population** dataset contains ZIP-code‚Äìlevel demographic information.  \n",
    "It includes **1,671 rows** and **3 variables**, all of which are numeric (`int64`).\n",
    "\n",
    "**Key takeaways:**\n",
    "- **Data quality:**  \n",
    "  - No missing values in any column.  \n",
    "  - Data types are correctly assigned as integers.  \n",
    "\n",
    "- **Structure and uniqueness:**  \n",
    "  - Each `Zip Code` is unique (1,671 distinct ZIP codes).  \n",
    "  - The `ID` column is also unique and functions only as an internal index ‚Äî it does not link to customers directly.  \n",
    "  - `Population` has 1,607 unique values, indicating some ZIP codes may have similar population sizes.  \n",
    "\n",
    "- **Numeric overview:**  \n",
    "  - `Zip Code` ranges from **90001 to 96161**, consistent with California ZIP codes.  \n",
    "  - `Population` ranges from **11** to **105,285**, with an average of about **20,276** people per ZIP code.  \n",
    "\n",
    "**Interpretation:**  \n",
    "This table provides **contextual demographic data** that can be linked to customers through their `Zip Code` from the **Location** table.  \n",
    "Since it operates at the **ZIP-code level**, it will be joined later via `Zip Code`, not `Customer ID`.  \n",
    "The `ID` column is only an index field and can be dropped before merging.\n",
    "\n",
    "\n",
    "\n",
    "### **Services:**  \n",
    "\n",
    "The **Services** dataset captures customer service usage, subscription details, and billing information.  \n",
    "It includes **7,043 customers** and **30 variables**, combining both service attributes and financial metrics.\n",
    "\n",
    "**Key takeaways:**\n",
    "- **Data quality:**  \n",
    "  - No missing values in most columns.  \n",
    "  - The columns `Offer` and `Internet Type` contain missing data (‚âà55% and 22% respectively), suggesting that not all customers were offered promotions or subscribed to Internet services.  \n",
    "  - Data types are consistent: numeric for billing and tenure, categorical for service indicators.  \n",
    "\n",
    "- **Numeric overview:**  \n",
    "  - `Count` is constant (=1) - can be dropped.  \n",
    "  - `Tenure in Months` ranges from **1 to 72**, indicating customer relationships lasting up to six years.  \n",
    "  - `Monthly Charge` varies from **$18.25 to $118.75** (mean ‚âà $64.8).  \n",
    "  - `Total Charges` and `Total Revenue` are highly variable, reflecting differences in service plans and tenure.  \n",
    "  - Financial columns such as `Total Refunds`, `Total Extra Data Charges`, and `Total Long Distance Charges` are mostly small relative to overall revenue.  \n",
    "\n",
    "- **Categorical overview:**  \n",
    "  - `Quarter` = ‚ÄúQ3‚Äù for all entries - not informative.  \n",
    "  - Service adoption patterns:  \n",
    "    - **Phone Service:** 90% ‚ÄúYes‚Äù  \n",
    "    - **Internet Service:** 78% ‚ÄúYes‚Äù  \n",
    "    - **Contract:** Dominated by ‚ÄúMonth-to-Month‚Äù (~51%)  \n",
    "    - **Payment Method:** Most common is ‚ÄúBank Withdrawal‚Äù (~55%)  \n",
    "  - Value-added services (`Online Security`, `Streaming TV`, etc.) are mostly ‚ÄúNo,‚Äù suggesting many customers subscribe to basic plans.\n",
    "\n",
    "**Interpretation:**  \n",
    "This table provides a detailed view of **customer engagement and spending behaviour**.  \n",
    "It combines tenure, billing, and service usage information ‚Äî all of which are likely **strong predictors of churn**.  \n",
    "Columns like `Count` and `Quarter` can be dropped, while `Offer` and `Internet Type` require cleaning or imputation.  \n",
    "The mix of continuous (e.g., `Tenure in Months`, `Monthly Charge`) and binary categorical features will be useful for both descriptive and predictive analyses.\n",
    "\n",
    "\n",
    "\n",
    "### **Status:**  \n",
    "\n",
    "The **Status** dataset captures customer satisfaction, churn outcomes, and value metrics.  \n",
    "It contains **7,043 customers** and **11 variables**, mixing satisfaction scores, churn labels, and lifetime value indicators.\n",
    "\n",
    "**Key takeaways:**\n",
    "- **Data quality:**  \n",
    "  - No missing values for most columns.  \n",
    "  - The fields `Churn Category` and `Churn Reason` have missing data in **‚âà73% of rows**, which aligns with the fact that these fields are only populated for customers who have churned.  \n",
    "  - Data types are correctly assigned (`int64` for numerical measures, `object` for categorical variables).  \n",
    "\n",
    "- **Numeric overview:**  \n",
    "  - `Count` is constant (=1) - can be dropped.  \n",
    "  - `Satisfaction Score` ranges from **1 to 5** (mean ‚âà 3.24).  \n",
    "  - `Churn Score` ranges from **5 to 96** (mean ‚âà 58.5), showing a wide variation in churn risk.  \n",
    "  - `CLTV` (Customer Lifetime Value) ranges from **2003 to 6500**, indicating differing customer profitability levels.  \n",
    "\n",
    "- **Categorical overview:**  \n",
    "  - `Quarter` = ‚ÄúQ3‚Äù for all entries - not informative.  \n",
    "  - `Customer Status`:  \n",
    "    - **Stayed** ‚Äì 4,720 customers  \n",
    "    - **Churned** ‚Äì 1,869 customers  \n",
    "    - **Joined** ‚Äì 454 customers  \n",
    "  - `Churn Label`: Binary ‚ÄúYes‚Äù/‚ÄúNo‚Äù indicator of churn (Yes = 1,869; No = 5,174).  \n",
    "  - `Churn Category`: 5 categories for churned customers (most common: *Competitor*).  \n",
    "  - `Churn Reason`: 20 reasons reported (most frequent: *Competitor had better devices*).  \n",
    "\n",
    "**Interpretation:**  \n",
    "This table provides the **core churn information** and customer satisfaction measures ‚Äî the foundation for our prediction target.  \n",
    "`Churn Label` will serve as the **dependent variable (target)** in the churn prediction model.  \n",
    "Columns such as `Count` and `Quarter` are not useful analytically and can be removed.  \n",
    "Although `Churn Category` and `Churn Reason` have many missing values, they still offer valuable insight for **post-model interpretation** and business recommendations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
