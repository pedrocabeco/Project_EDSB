{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80709d95",
   "metadata": {},
   "source": [
    "Load the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0c70702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook dir: /Users/pedro.cabeco/Project_EDSB-1/notebooks\n",
      "DATA_RAW: /Users/pedro.cabeco/Project_EDSB-1/data/raw\n",
      "Exists? True\n",
      "CSV files: ['Telco_customer_churn_status.csv', 'Telco_customer_churn_services.csv', 'Telco_customer_churn_demographics.csv', 'Telco_customer_churn_location.csv', 'Telco_customer_churn_population.csv']\n",
      "Demographics -> (7043, 9)\n",
      "Location     -> (7043, 9)\n",
      "Population   -> (1671, 3)\n",
      "Services     -> (7043, 30)\n",
      "Status       -> (7043, 11)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Find the folder where this notebook lives\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "# Go from this notebook folder to the raw data folder\n",
    "#    \"../data/raw\" means:\n",
    "#    - \"..\"  -> go up one folder (out of 'Pedro' and back to 'Sandbox')\n",
    "#    - \"data/raw\" -> go into 'data', then into 'raw'\n",
    "DATA_RAW = (NOTEBOOK_DIR / \"../data/raw\").resolve()\n",
    "\n",
    "print(\"Notebook dir:\", NOTEBOOK_DIR)\n",
    "print(\"DATA_RAW:\", DATA_RAW)\n",
    "print(\"Exists?\", DATA_RAW.exists())\n",
    "print(\"CSV files:\", [p.name for p in DATA_RAW.glob(\"*.csv\")])\n",
    "\n",
    "# Load all CSV files into Pandas DataFrames\n",
    "demographics = pd.read_csv(DATA_RAW / \"Telco_customer_churn_demographics.csv\")\n",
    "location     = pd.read_csv(DATA_RAW / \"Telco_customer_churn_location.csv\")\n",
    "population   = pd.read_csv(DATA_RAW / \"Telco_customer_churn_population.csv\")\n",
    "services     = pd.read_csv(DATA_RAW / \"Telco_customer_churn_services.csv\")\n",
    "status       = pd.read_csv(DATA_RAW / \"Telco_customer_churn_status.csv\")\n",
    "\n",
    "# Print shapes just to confirm\n",
    "for name, df in {\n",
    "    \"Demographics\": demographics,\n",
    "    \"Location\": location,\n",
    "    \"Population\": population,\n",
    "    \"Services\": services,\n",
    "    \"Status\": status,\n",
    "}.items():\n",
    "    print(f\"{name:12s} -> {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc8049f",
   "metadata": {},
   "source": [
    "Make “clean” copies and remove useless columns\n",
    "\n",
    "Some columns have the same value for every row (like Count = 1), or don’t add anything new (Quarter = \"Q3\" for everyone, or Country = \"United States\" for everyone). These don’t help the model and just add noise.\n",
    "\n",
    "We will:\n",
    "\n",
    "- Make copies of the original tables (so we don’t ruin the raw data).\n",
    "- Drop columns that are constant or clearly redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448a86cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographics (clean) -> (7043, 8)\n",
      "Location (clean)     -> (7043, 5)\n",
      "Population (clean)   -> (1671, 2)\n",
      "Services (clean)     -> (7043, 28)\n",
      "Status (clean)       -> (7043, 9)\n"
     ]
    }
   ],
   "source": [
    "# Make copies, so we leave the original DataFrames untouched\n",
    "demo_clean = demographics.copy()\n",
    "loc_clean  = location.copy()\n",
    "pop_clean  = population.copy()\n",
    "serv_clean = services.copy()\n",
    "stat_clean = status.copy()\n",
    "\n",
    "# ---- Demographics: drop 'Count' (always 1)\n",
    "demo_clean = demo_clean.drop(columns=[\"Count\"])\n",
    "\n",
    "# ---- Location:\n",
    "# - 'Count' is always 1\n",
    "# - 'Country' is always \"United States\"\n",
    "# - 'State' is always \"California\"\n",
    "# - 'Lat Long' is just text version of (Latitude, Longitude)\n",
    "loc_clean = loc_clean.drop(columns=[\"Count\", \"Country\", \"State\", \"Lat Long\"])\n",
    "\n",
    "# ---- Population:\n",
    "# - 'ID' is just an internal index, doesn't link to customers\n",
    "pop_clean = pop_clean.drop(columns=[\"ID\"])\n",
    "\n",
    "# ---- Services:\n",
    "# - 'Count' is always 1\n",
    "# - 'Quarter' is always \"Q3\"\n",
    "serv_clean = serv_clean.drop(columns=[\"Count\", \"Quarter\"])\n",
    "\n",
    "# ---- Status:\n",
    "# - same reasoning as Services\n",
    "stat_clean = stat_clean.drop(columns=[\"Count\", \"Quarter\"])\n",
    "\n",
    "# Check new shapes\n",
    "for name, df in {\n",
    "    \"Demographics (clean)\": demo_clean,\n",
    "    \"Location (clean)\": loc_clean,\n",
    "    \"Population (clean)\": pop_clean,\n",
    "    \"Services (clean)\": serv_clean,\n",
    "    \"Status (clean)\": stat_clean,\n",
    "}.items():\n",
    "    print(f\"{name:20s} -> {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c314b",
   "metadata": {},
   "source": [
    "Fix missing values where the meaning is obvious\n",
    "\n",
    "Two columns in services have missing values:\n",
    "\n",
    "- Offer – if it’s empty, it likely means no promo offer was given.\n",
    "- Internet Type – missing when Internet Service = \"No\" (they simply don’t have internet).\n",
    "\n",
    "We translate these into explicit labels so the model doesn’t see them as “mystery gaps”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e40462fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internet Service</th>\n",
       "      <th>Internet Type</th>\n",
       "      <th>Offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No Offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>Offer E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>Offer D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>Offer C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>Offer C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Internet Service Internet Type     Offer\n",
       "0              Yes           DSL  No Offer\n",
       "1              Yes   Fiber Optic   Offer E\n",
       "2              Yes   Fiber Optic   Offer D\n",
       "3              Yes   Fiber Optic   Offer C\n",
       "4              Yes   Fiber Optic   Offer C"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Fix 'Offer'\n",
    "# If Offer is NaN (missing), we treat it as \"No Offer\"\n",
    "serv_clean[\"Offer\"] = serv_clean[\"Offer\"].fillna(\"No Offer\")\n",
    "\n",
    "# If Internet Service = \"No\" → Internet Type = \"None\" (no condition on NaN)\n",
    "serv_clean.loc[serv_clean[\"Internet Service\"].eq(\"No\"), \"Internet Type\"] = \"No Internet\"\n",
    "\n",
    "# Any remaining NaN (weird cases) → \"Unknown\"\n",
    "serv_clean[\"Internet Type\"] = serv_clean[\"Internet Type\"].fillna(\"Unknown\")\n",
    "\n",
    "# Sanity check\n",
    "serv_clean[\"Internet Type\"].value_counts(dropna=False)\n",
    "\n",
    "# Quick peek\n",
    "serv_clean[[\"Internet Service\", \"Internet Type\", \"Offer\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd63fd5",
   "metadata": {},
   "source": [
    "Merge all customer-level tables by Customer ID\n",
    "\n",
    "Now we want to build one big table where each row is:\n",
    "\n",
    "- one customer, with demographics + location + services + status.\n",
    "\n",
    "Customer ID is the key that appears in all four of those tables.\n",
    "\n",
    "We will do a sequence of left joins:\n",
    "\n",
    "- Start from demo_clean\n",
    "- Add loc_clean\n",
    "- Add serv_clean\n",
    "- Add stat_clean\n",
    "\n",
    "“Left join” means: keep all customers from the left table even if the right table is missing something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e783a359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer-level merged shape: (7043, 47)\n",
      "Number of duplicate Customer IDs: 0\n",
      "\n",
      "Churn Label counts:\n",
      "Churn Label\n",
      "No     5174\n",
      "Yes    1869\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge 4 customer-level tables on 'Customer ID'\n",
    "cust_merged = (\n",
    "    demo_clean\n",
    "    .merge(loc_clean,  on=\"Customer ID\", how=\"left\")\n",
    "    .merge(serv_clean, on=\"Customer ID\", how=\"left\")\n",
    "    .merge(stat_clean, on=\"Customer ID\", how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"Customer-level merged shape:\", cust_merged.shape)\n",
    "\n",
    "# Check that each Customer ID appears only once\n",
    "dup_ids = cust_merged[\"Customer ID\"].duplicated().sum()\n",
    "print(\"Number of duplicate Customer IDs:\", dup_ids)\n",
    "\n",
    "# Basic sanity check: see the churn label distribution\n",
    "print(\"\\nChurn Label counts:\")\n",
    "print(cust_merged[\"Churn Label\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec24a6a",
   "metadata": {},
   "source": [
    "Add ZIP-code-level population via Zip Code\n",
    "\n",
    "The population table is different: it doesn’t have one row per customer.\n",
    "It has one row per ZIP code.\n",
    "\n",
    "So we merge it using Zip Code (which lives inside loc_clean and is already inside cust_merged now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e35d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (7043, 48)\n",
      "Customers without population info: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Population</th>\n",
       "      <th>Tenure in Months</th>\n",
       "      <th>Monthly Charge</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Customer Status</th>\n",
       "      <th>Churn Label</th>\n",
       "      <th>Churn Value</th>\n",
       "      <th>Churn Score</th>\n",
       "      <th>CLTV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8779-QRDMV</td>\n",
       "      <td>Male</td>\n",
       "      <td>78</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90022</td>\n",
       "      <td>68701</td>\n",
       "      <td>1</td>\n",
       "      <td>39.65</td>\n",
       "      <td>59.65</td>\n",
       "      <td>3</td>\n",
       "      <td>Churned</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>5433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7495-OOKFY</td>\n",
       "      <td>Female</td>\n",
       "      <td>74</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90063</td>\n",
       "      <td>55668</td>\n",
       "      <td>8</td>\n",
       "      <td>80.65</td>\n",
       "      <td>1024.10</td>\n",
       "      <td>3</td>\n",
       "      <td>Churned</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>5302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1658-BYGOY</td>\n",
       "      <td>Male</td>\n",
       "      <td>71</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90065</td>\n",
       "      <td>47534</td>\n",
       "      <td>18</td>\n",
       "      <td>95.45</td>\n",
       "      <td>1910.88</td>\n",
       "      <td>2</td>\n",
       "      <td>Churned</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>3179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4598-XLKNJ</td>\n",
       "      <td>Female</td>\n",
       "      <td>78</td>\n",
       "      <td>Inglewood</td>\n",
       "      <td>90303</td>\n",
       "      <td>27778</td>\n",
       "      <td>25</td>\n",
       "      <td>98.50</td>\n",
       "      <td>2995.07</td>\n",
       "      <td>2</td>\n",
       "      <td>Churned</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>5337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4846-WHAFZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>80</td>\n",
       "      <td>Whittier</td>\n",
       "      <td>90602</td>\n",
       "      <td>26265</td>\n",
       "      <td>37</td>\n",
       "      <td>76.50</td>\n",
       "      <td>3102.36</td>\n",
       "      <td>2</td>\n",
       "      <td>Churned</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>2793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer ID  Gender  Age         City  Zip Code  Population  \\\n",
       "0  8779-QRDMV    Male   78  Los Angeles     90022       68701   \n",
       "1  7495-OOKFY  Female   74  Los Angeles     90063       55668   \n",
       "2  1658-BYGOY    Male   71  Los Angeles     90065       47534   \n",
       "3  4598-XLKNJ  Female   78    Inglewood     90303       27778   \n",
       "4  4846-WHAFZ  Female   80     Whittier     90602       26265   \n",
       "\n",
       "   Tenure in Months  Monthly Charge  Total Revenue  Satisfaction Score  \\\n",
       "0                 1           39.65          59.65                   3   \n",
       "1                 8           80.65        1024.10                   3   \n",
       "2                18           95.45        1910.88                   2   \n",
       "3                25           98.50        2995.07                   2   \n",
       "4                37           76.50        3102.36                   2   \n",
       "\n",
       "  Customer Status Churn Label  Churn Value  Churn Score  CLTV  \n",
       "0         Churned         Yes            1           91  5433  \n",
       "1         Churned         Yes            1           69  5302  \n",
       "2         Churned         Yes            1           81  3179  \n",
       "3         Churned         Yes            1           88  5337  \n",
       "4         Churned         Yes            1           67  2793  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge ZIP-level population info using 'Zip Code'\n",
    "full_df = cust_merged.merge(pop_clean, on=\"Zip Code\", how=\"left\")\n",
    "\n",
    "print(\"Full dataset shape:\", full_df.shape)\n",
    "\n",
    "# How many customers don't have a matching population row?\n",
    "missing_pop = full_df[\"Population\"].isna().sum()\n",
    "print(\"Customers without population info:\", missing_pop)\n",
    "\n",
    "# Peek at some important columns\n",
    "key_cols = [\n",
    "    \"Customer ID\",\n",
    "    \"Gender\",\n",
    "    \"Age\",\n",
    "    \"City\",\n",
    "    \"Zip Code\",\n",
    "    \"Population\",\n",
    "    \"Tenure in Months\",\n",
    "    \"Monthly Charge\",\n",
    "    \"Total Revenue\",\n",
    "    \"Satisfaction Score\",\n",
    "    \"Customer Status\",\n",
    "    \"Churn Label\",\n",
    "    \"Churn Value\",\n",
    "    \"Churn Score\",\n",
    "    \"CLTV\",\n",
    "]\n",
    "\n",
    "full_df[key_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb7442c",
   "metadata": {},
   "source": [
    "We’ll create a data/processed folder next to data/raw and save the final table there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fa8a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved files:\n",
      " - /Users/pedro.cabeco/Project_EDSB-1/data/processed/telco_churn_master.csv\n"
     ]
    }
   ],
   "source": [
    "# Create processed data folder (if it doesn't exist yet)\n",
    "DATA_PROCESSED = (NOTEBOOK_DIR / \"../data/processed\").resolve()\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save as CSV\n",
    "output_csv = DATA_PROCESSED / \"telco_churn_master.csv\"\n",
    "full_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"Saved files:\")\n",
    "print(\" -\", output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telco-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
